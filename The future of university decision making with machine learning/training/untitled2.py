# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JAAR0OSvw5u3-1fZILD2_xCakwv5lG1B
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import pickle
import matplotlib.pyplot as plt
# %matplotlib inline 
import seaborn as sns
import sklearn
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
import imblearn
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

df = pd.read_csv("/content/Admission_Predict.csv")
df

df.head()

df.drop(["Serial No."],axis=1,inplace=True)
df.head()



df.describe()

df.info()

df.isnull().any()

df.corr()

plt.figure(figsize=(10,7))
sns.heatmap(df.corr(),annot=True,cmap="RdYlGn")

sns.pairplot(data=df,hue='Research',markers=["^", "v"],palette='inferno')

sns.scatterplot(x='University Rating',y='CGPA',data=df,color='Red',s=100)

category = ['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research','Chance of Admit']
color = ['yellowgreen','gold','lightskyblue','pink','red','purple','orange','gray']
start = True
for i in np.arange(4):
    fip = plt.figure(figsize=(14,8))
    plt.subplot2grid((4,2),(i,0))
    df[category[2*i]].hist(color=color[2*i],bins=10)
    plt.title(category[2*i])
    plt.subplot2grid((4,2),(i,1))
    df[category[2*i+1]].hist(color=color[2*i+1],bins=10)
    plt.title(category[2*i+1])

plt.subplots_adjust(hspace = 0.7,wspace = 0.2)
plt.show()

print('Mean CGPA Score is :',int(df['CGPA'].mean()))
print('Mean GRE Score is :',int(df['GRE Score'].mean()))
print('Mean TOEFL Score is :',int(df['TOEFL Score'].mean()))

df.head()

x=df.iloc[:,0:-1].values
x

y=df.iloc[:,7:].values
y

from sklearn.preprocessing import MinMaxScaler
sc= MinMaxScaler()
x=sc.fit_transform(x)
x

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20,random_state=42)

y_train.shape

x_train

y_train=(y_train>0.5)
y_train

y_test=(y_test>0.5)

y_test

def logreg(x_train,x_test,y_train,y_test):
  lr = LogisticRegression(random_state=0)
  lr.fit(x_train,y_train)
  y_lr_tr = lr.predict(x_train)
  print(accuracy_score(y_lr_tr,y_train))
  yPred_lr = lr.predict(x_test)
  print(accuracy_score(yPred_lr,y_test))
  print("***Logisitic Regression***")
  print("Confusion_Matrix")
  print(confusion_matrix(y_test,yPred_lr))
  print("Classification Report")
  print(classification_report(y_test,yPred_lr))

logreg(x_train,x_test,y_train,y_test)

lr=LogisticRegression(random_state=0)
lr.fit(x_train,y_train)
print("predicting on test values")
lr_pred =lr.predict(x_test)
print("output is: ",lr_pred)
print("predicting on random input")
lr_pred_own = lr.predict(sc.transform([[337,118,4,4.5,4.5,9.65,1]]))
print("output is: ",lr_pred_own)

def RandomForest(x_train,x_test,y_train,y_test):
  rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
  rf.fit(x_train,y_train)
  y_rf_tr = rf.predict(x_train)
  print(accuracy_score(y_rf_tr,y_train))
  ypred_rf = rf.predict(x_test)
  print(accuracy_score(ypred_rf,y_test))
  print("***Random Forest***")
  print("Confusion_Matrix")
  print(confusion_matrix(y_test,ypred_rf))
  print("Classification Report")
  print(classification_report(y_test,ypred_rf))

RandomForest(x_train,x_test,y_train,y_test)

rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
rf.fit(x_train,y_train)
print("predicting on test values")
rf_pred =rf.predict(x_test)
print("output is: ",rf_pred)
print("predicting on random input")
rf_pred_own = rf.predict(sc.transform([[337,118,4,4.5,4.5,9.65,1]]))
print("output is: ",rf_pred_own)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()

classifier.add(Dense(units=7, activation='relu',  input_dim=7))

classifier.add(Dense(units=7, activation='relu'))

classifier.add(Dense(units=1, activation='linear'))

classifier.compile(optimizer='adam', loss='binary_crossentrop',metrics=['accuracy'])

model=classifier.fit(x_train, y_train, batch_size=10, validation_split=0.33, epochs=20)

ann_pred = classifier.predict(x_test)
ann_pred = (ann_pred>0.5)
print(accuracy_score(ann_pred,y_test))
print("***ANN Model***")
print("Confusion_Matrix")
print(confusion_matrix(y_test,ann_pred))
print("Classification Report")
print(classification_report(y_test,ann_pred))

pickle.dump(lr,open('university.pkl','wb'))

